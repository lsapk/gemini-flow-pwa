
import { serve } from "https://deno.land/std@0.186.0/http/server.ts";
import { GoogleGenerativeAI } from "https://esm.sh/@google/generative-ai@0.24.1?target=deno";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.39.2?target=deno";

// Define CORS headers for browser requests
const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

interface ChatMessage {
  role: "user" | "assistant";
  content: string;
}

type LanguageCode = "fr" | "en" | "es" | "de";

// Helper function to get prompt based on language
function getSystemPrompt(language: LanguageCode = "fr"): string {
  const prompts = {
    fr: `Tu es DeepFlow, un assistant IA sp√©cialis√© dans la productivit√©, le bien-√™tre et le d√©veloppement personnel. Voici comment tu dois r√©pondre :

1. Utilise du markdown riche avec des emojis pertinents pour structurer tes r√©ponses.
2. Sois concis mais complet, en utilisant des listes et des titres pour organiser l'information.
3. Propose toujours des conseils pratiques et applicables imm√©diatement.
4. Adapte ton ton pour √™tre encourageant et positif.
5. N'h√©site pas √† utiliser des m√©taphores ou des exemples concrets.

Si tu ne connais pas la r√©ponse, admets-le simplement et sugg√®re o√π l'utilisateur pourrait trouver l'information.`,

    en: `You are DeepFlow, an AI assistant specialized in productivity, wellbeing, and personal development. Here's how you should respond:

1. Use rich markdown with relevant emojis to structure your answers.
2. Be concise but complete, using lists and headings to organize information.
3. Always offer practical advice that can be applied immediately.
4. Adapt your tone to be encouraging and positive.
5. Don't hesitate to use metaphors or concrete examples.

If you don't know the answer, simply admit it and suggest where the user might find the information.`,

    es: `Eres DeepFlow, un asistente de IA especializado en productividad, bienestar y desarrollo personal. As√≠ es como debes responder:

1. Utiliza markdown enriquecido con emojis relevantes para estructurar tus respuestas.
2. S√© conciso pero completo, utilizando listas y t√≠tulos para organizar la informaci√≥n.
3. Ofrece siempre consejos pr√°cticos que puedan aplicarse inmediatamente.
4. Adapta tu tono para ser alentador y positivo.
5. No dudes en utilizar met√°foras o ejemplos concretos.

Si no conoces la respuesta, simplemente adm√≠telo y sugiere d√≥nde podr√≠a encontrar la informaci√≥n el usuario.`,

    de: `Du bist DeepFlow, ein KI-Assistent, der auf Produktivit√§t, Wohlbefinden und pers√∂nliche Entwicklung spezialisiert ist. So solltest du antworten:

1. Verwende umfangreiches Markdown mit relevanten Emojis, um deine Antworten zu strukturieren.
2. Sei pr√§zise, aber umfassend und verwende Listen und √úberschriften zur Organisation der Informationen.
3. Biete immer praktische Ratschl√§ge an, die sofort umgesetzt werden k√∂nnen.
4. Passe deinen Ton an, um ermutigend und positiv zu sein.
5. Z√∂gere nicht, Metaphern oder konkrete Beispiele zu verwenden.

Wenn du die Antwort nicht kennst, gib es einfach zu und schlage vor, wo der Benutzer die Information finden k√∂nnte.`
  };

  return prompts[language] || prompts.fr;
}

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    // Get API key from environment variable
    const GEMINI_API_KEY = Deno.env.get("GEMINI_API_KEY");
    if (!GEMINI_API_KEY) {
      throw new Error("GEMINI_API_KEY is not set in environment variables");
    }

    // Get Supabase credentials from environment
    const SUPABASE_URL = Deno.env.get("SUPABASE_URL") || "";
    const SUPABASE_ANON_KEY = Deno.env.get("SUPABASE_ANON_KEY") || "";
    const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") || "";

    // Parse request body
    const { message, chatHistory, userId, custom_prompt } = await req.json();
    
    if (!message) {
      throw new Error("Message is required");
    }
    
    if (!userId) {
      throw new Error("User ID is required");
    }

    // Initialize Supabase client with service role for admin access
    const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);

    // Get user's language preference
    const { data: userSettings, error: settingsError } = await supabase
      .from('user_settings')
      .select('language')
      .eq('id', userId)
      .maybeSingle();

    if (settingsError) {
      console.error("Error fetching user settings:", settingsError);
    }
      
    const userLanguage = userSettings?.language || "fr" as LanguageCode;

    // Check if user is admin or premium
    const { data: subscriptionData } = await supabase
      .from('subscribers')
      .select('subscribed')
      .eq('user_id', userId)
      .maybeSingle();
      
    const { data: roleData } = await supabase
      .from('user_roles')
      .select('role')
      .eq('user_id', userId)
      .eq('role', 'admin')
      .maybeSingle();
      
    const isAdmin = roleData?.role === 'admin';
    const isPremium = (subscriptionData?.subscribed === true) || isAdmin;

    // If user is not premium, check request limits
    if (!isPremium) {
      // Get today's date (UTC midnight)
      const today = new Date();
      today.setHours(0, 0, 0, 0);
      
      // Count user's requests today
      const { count, error } = await supabase
        .from('ai_requests')
        .select('*', { count: 'exact', head: false })
        .eq('service', 'chat')
        .eq('user_id', userId)
        .gte('created_at', today.toISOString());
        
      if (error) {
        throw new Error(`Error checking AI request limit: ${error.message}`);
      }
      
      const requestsToday = count || 0;
      
      // If user has reached the limit, return an error
      if (requestsToday >= 5) {
        const limitMessage = {
          fr: "‚ö†Ô∏è **Limite atteinte**\n\nVous avez atteint votre limite de 5 requ√™tes quotidiennes avec le compte gratuit. Passez √† un abonnement premium pour b√©n√©ficier d'un acc√®s illimit√©.",
          en: "‚ö†Ô∏è **Limit reached**\n\nYou have reached your limit of 5 daily requests with the free account. Upgrade to a premium subscription for unlimited access.",
          es: "‚ö†Ô∏è **L√≠mite alcanzado**\n\nHas alcanzado tu l√≠mite de 5 solicitudes diarias con la cuenta gratuita. Actualiza a una suscripci√≥n premium para obtener acceso ilimitado.",
          de: "‚ö†Ô∏è **Limit erreicht**\n\nSie haben Ihr Limit von 5 t√§glichen Anfragen mit dem kostenlosen Konto erreicht. Upgrade auf ein Premium-Abonnement f√ºr unbegrenzten Zugriff."
        };
        
        return new Response(
          JSON.stringify({ response: limitMessage[userLanguage] || limitMessage.fr }),
          { headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
    }

    // Track this request in the database
    await supabase
      .from('ai_requests')
      .insert({ 
        service: 'chat',
        user_id: userId
      });

    // Initialize the Google Generative AI
    const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
    
    // Prepare history for the model with a maximum of 10 messages to prevent context overflow
    const MAX_HISTORY_MESSAGES = 10;
    const history: ChatMessage[] = chatHistory || [];
    const recentHistory = history.slice(-MAX_HISTORY_MESSAGES);

    // Use custom prompt if provided (for analysis function), otherwise use default system prompt
    const systemInstruction = custom_prompt || getSystemPrompt(userLanguage);

    try {
      // Create chat session with the Gemini model
      const model = genAI.getGenerativeModel({ 
        model: "gemini-1.5-flash",
        systemInstruction: systemInstruction
      });

      // Convert history to Google's chat format
      const googleChatHistory = recentHistory.map(msg => ({
        role: msg.role === "user" ? "user" : "model",
        parts: [{ text: msg.content }]
      }));

      // Start chat and send the user's message
      const chat = model.startChat({
        history: googleChatHistory,
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 2048,
        },
      });

      const result = await chat.sendMessage(message);
      const response = result.response;
      const responseText = response.text();

      return new Response(
        JSON.stringify({ response: responseText }),
        {
          headers: {
            ...corsHeaders,
            "Content-Type": "application/json",
          },
        }
      );
    } catch (error) {
      console.error("Error with Gemini model:", error);
      
      // Fallback response in case of API failure
      const fallbackResponse = {
        fr: "üôÅ **D√©sol√©, je rencontre des difficult√©s techniques**\n\nLe service Gemini AI est temporairement indisponible. Veuillez r√©essayer dans quelques instants.",
        en: "üôÅ **Sorry, I'm experiencing technical difficulties**\n\nThe Gemini AI service is temporarily unavailable. Please try again in a few moments.",
        es: "üôÅ **Lo siento, estoy experimentando dificultades t√©cnicas**\n\nEl servicio Gemini AI no est√° disponible temporalmente. Por favor, int√©ntalo de nuevo en unos instantes.",
        de: "üôÅ **Es tut mir leid, ich habe technische Schwierigkeiten**\n\nDer Gemini AI-Dienst ist vor√ºbergehend nicht verf√ºgbar. Bitte versuchen Sie es in wenigen Augenblicken erneut."
      };
      
      return new Response(
        JSON.stringify({ response: fallbackResponse[userLanguage] || fallbackResponse.fr }),
        {
          headers: {
            ...corsHeaders,
            "Content-Type": "application/json",
          },
        }
      );
    }
  } catch (error) {
    console.error("Error processing chat request:", error);
    
    return new Response(
      JSON.stringify({
        error: error.message,
        response: "‚ö†Ô∏è **Une erreur est survenue**\n\nImpossible de traiter votre demande pour le moment. Veuillez r√©essayer plus tard."
      }),
      {
        status: 500,
        headers: {
          ...corsHeaders,
          "Content-Type": "application/json",
        },
      }
    );
  }
});
